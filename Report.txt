** 00 - Logistic Regression **

First file contains simple tf-idf vectorizing of messages and application of logistic regression. The model yields quite good results:

             precision    recall  f1-score   support

        ham       0.99      0.98      0.99      1585
       spam       0.90      0.94      0.92       255

avg / total       0.98      0.98      0.98      1840

[[1558   27]
 [  15  240]]

However, one can notice two main problems with the result:
1) precision for spam recognition is high, but still significant number of ham messages are classified as spam. It is undesirable effect, as an end-user of the system might overlook important messages that will be classified as spam.
2) TF-IDF Vectorizer yielded a matrix with a 7097 features. It was trained on not so big language corpus (5574 sms messages). Thus, the vectorizer might vectorize some future messages poorly, if words contained in those future messages are different from the words contained in the training set. As a result, the model might also not perform very well on those messages.

AD 1) 

To address the first issue, one can try to test different thresholds of Logistic Regression classificator - trying to improve precision and not losing to much on recall at the same time. We ploted precisions and recalls of ham and spam classifications for different thresholds in (0.5, 1) interval to see which one will perform best. For t = 0.7 we got quite a noticable boost in Spam Precision. Spam Recall was still on satisfactory level. 
When we tested this value of threshold on the data from the test set, weighted f1-score was 0.98 - so the same as in the standard model with t = 0.5. Moreover, we got only 5 ham messages classified as spam (so the result was more than 5 times better than in standard model).

             precision    recall  f1-score   support

        ham       0.98      1.00      0.99      1585
       spam       0.98      0.89      0.93       255

avg / total       0.98      0.98      0.98      1840

[[1580    5]
 [  29  226]]

Thus, we aquired satisfactory model with very high precision for spam detection and solid recall. However, using a custom threshold value might not be the best solution for some instances of data, that we did not test during our modeling process. Therefore, one can be still worried about the recall of the model. That is why we will try to explore different approaches and try to find even better model.

** 01 - Gradient Boosting **

We tried using Gradient Boosting Classifier, as we thought it might perform better than Logistic Regression in our case. Indeed, after experimenting a little bit with parameters of the model, we obtained a better Classifier:

             precision    recall  f1-score   support

        ham       0.98      1.00      0.99      1585
       spam       0.99      0.89      0.94       255

avg / total       0.98      0.98      0.98      1840

[[1582    3]
 [  27  228]]

The model was better than standard Logistic Regression and better than our customized Logistic Regression. Spam precision was really good (only 3 ham messages classified as spam) and Spam recall was better as well. Still some Spam messages were classified as Ham. 

In order to check if we could improve the model even further we tried to build an ensemble model that would include both Logistic Regression and Gradient Boosting. Indeed the obtained model was even better:

             precision    recall  f1-score   support

        ham       0.98      1.00      0.99      1585
       spam       0.99      0.90      0.94       255

avg / total       0.99      0.99      0.99      1840

[[1583    2]
 [  25  230]]

AD 2)

** 02 - Using Glove **

In order to address the problem of small training set (TF-IDF Vectorizer yielded a matrix with a 7097 features), we decided to use Glove pre-trained vectors for vectorizing the data. That is how an obtained model would be able to classify effectively even messages with words that were not in the training set (in previous approaches the vectorizer would transform such messages to vector with mostly zeros and the model would be likely to perform poorly). 

Idea to address this issue is to use Glove (https://nlp.stanford.edu/projects/glove/) to provide the semantic connotations between the words in our traing set and words from future data.

The Gradient Boosting Classifier build on such vectorization turned out to also perform well:

             precision    recall  f1-score   support

        ham       0.98      1.00      0.99      1585
       spam       0.98      0.87      0.92       255

avg / total       0.98      0.98      0.98      1840

[[1580    5]
 [  33  222]]

The model was a little bit worse than the best one that we aquired. However, it was still very solid model - comparable with customized Logistic Regression model from 00 iteration.

The big advantage of this model is though, that it can classify messages even with words that were not present in the training set (because it uses pre-trained word vectors). Considering the fact that the training set was rather small, this is a very useful finding.

** Future Work **

Future iteration on this classification task could include building even better ensemble models after experimenting with different classificators. The other challenge worth thinking about is how to limit the size of Glove pre-trained vectors (now it's over 5GB), as it may time consuming to load it all in some use cases. Another thing worth thinking about is how to enlarge the training set for future iterations, as for now it can be not fully representative for proper spam classification.


